---
title: "Impact_model_inputs.Rmd"
author: "Lauren Knose"
date: "2024-06-01"
output: html_document
editor_options: 
  chunk_output_type: console
---

The purpose of this program is to prepare data for input into models.


# Step 1. Load dependent packages and data needed:

a) Loading dependent packages...
```{r}
library(zoo) #needed to interpolate NA values (na.approx function)
library(ggplot2) #needed for plots
library(ggpubr) #needed to plot two plots in one graph
library(dplyr) #needed for reshaping/reformating data
```

b) Loading data...
Note, ensure date data is formatted in R as Date.

```{r}
cyanoHAB<- read.csv(file="Cleaned_data/cyanoHAB_severity.csv")
extLoad<- read.csv(file="Cleaned_data/TotalP_allext.csv")
intLoad<- read.csv(file="Cleaned_data/TotalP_allint.csv")
```

# Step 2. Calculate weekly loads: 

a) merging and filtering data...
Note, you can only merge two files at one time.

```{r}
### remove unecessary fields ###
intLoad2<- intLoad %>%
  mutate(sampledate.x=NULL, sampledate.y=NULL, X=NULL)

extLoad2<- extLoad %>%
  select(!c(sampledate, dryP_atm_kgday, wetP_atm_kgday, totP_atm_kgday, X))

### merge load tables ###
loads<- merge(intLoad2, extLoad2, #daily estimates
               by.x=c("Yr", "daynum"), #key fields in x data frame
               by.y=c("Yr", "daynum"), #key fields in y data frame
               all=TRUE)
```

Data frames merged.

b) defining the weekly observation sequence...

```{r}
### define the time sequence needed ###
week_bins<-seq(from=196, 
                  to=252, #define date end of cyanoHAB season
                  by=7) #creates a sequence every 7 days 
week_bins
```

Weekly observation bins determined as sequence 1 to 14.

c) calculating total loads for each lag...

```{r}
all_loads<- loads %>%
  select(Yr, daynum, Int_TotP_kgday, TotP_HEratio, Pext_kgday, Pext_kgday_CF1) %>%
  group_by(Yr) %>%
  mutate(Pext=rollapply(Pext_kgday, width=7, align="right", FUN=function(x) mean(x[-1], na.rm=TRUE),fill=NA, partial=TRUE),
         Pext_k7=lag(Pext, n=7),
         Pext_k14=lag(Pext, n=14),
         Pext_k21=lag(Pext, n=21),
         Pext_k28=lag(Pext, n=28),
         Pint=rollapply(Int_TotP_kgday, width=7, align="right", FUN=function(x) mean(x[-1], na.rm=TRUE),fill=NA, partial=TRUE),
         Pint_k7=lag(Pint, n=7),
         Pint_k14=lag(Pint, n=14),
         Pint_k21=lag(Pint, n=21),
         Pint_k28=lag(Pint, n=28),
         Pratio=TotP_HEratio,
         Pratio_k7=lag(Pratio, n=7),
         Pratio_k14=lag(Pratio, n=14),
         Pratio_k21=lag(Pratio, n=21),
         Pratio_k28=lag(Pratio, n=28),
         Pext_CF1=rollapply(Pext_kgday_CF1, width=7, align="right", FUN=function(x) mean(x[-1], na.rm=TRUE),fill=NA, partial=TRUE),
         Pext_CF1_k7=lag(Pext, n=7),
         Pext_CF1_k14=lag(Pext, n=14),
         Pext_CF1_k21=lag(Pext, n=21),
         Pext_CF1_k28=lag(Pext, n=28)) %>%
  ungroup() %>%
  filter(daynum %in% week_bins)
```

Weekly loads calculated.

# Step 3. Merge the response and predictor variables:

```{r}
inputs_weekly<- merge(all_loads, cyanoHAB,
                 by.x=c("Yr", "daynum"),
                 by.y=c("Yr", "daynum_bin"), all.y=TRUE)
```

Data files merged.

# Step 4. Save the data as new data files:

```{r}
### saving weekly data file ###
write.csv(inputs_weekly, file="Cleaned_data/Impact_model_weekly.csv")
```

# Step 5. View and summarize the data:

a) plotting precipitation for season by year...

```{r}
### summarize precipitation by year ###
fig4a_data<- loads %>%
  filter(daynum>=196 & daynum<=252) %>% #filter for cyanoHAB season
  select(Yr, Precipitation_in) %>%
  group_by(Yr) %>%
  summarize(Precip_inyr=sum(Precipitation_in)) %>%
  ungroup()
write.csv(fig4a_data, file="Products/Figure4a_data.csv")

### plot precipitation per year for cyanoHAB season ###
fig4a<- ggplot(data=fig4a_data, aes(x=as.character(Yr), y=Precip_inyr)) + 
  geom_bar(stat="identity", color="black", fill="grey")+ 
  theme_classic()+
  labs(x=NULL, y="Total Precipitation (in)", title="a)")
fig4a
```

Precipitation plotted.

b) plotting P loads for season by source and year...

```{r}
### sumarize loads by year ###
fig4b_data<- loads %>%
  filter(daynum>= 196 & daynum <= 252) %>% #filter for cyanoHAB season
  select(Yr, daynum, Int_TotP_kgday, Pext_kgday) %>%
  group_by(Yr) %>% # summarize by year
  summarize(Int_TotP_kg=sum(Int_TotP_kgday), 
            Pext_kg=sum(Pext_kgday)) %>%
  ungroup()
fig4b_data<- melt(fig4b_data, #the table you want to reshape wide to long
               id.vars=c("Yr"), #the column to use as unique id
               measure.vars=c("Int_TotP_kg","Pext_kg"), 
               #the columns where values will be taken
               variable.name="Source", #label the source of P loading
               value.name="TotP_kg") #label the value with units

### rename source loads ###               
fig4b_data$Source<-as.character(fig4b_data$Source) #tell R character data held
fig4b_data$Source[fig4b_data$Source=="Int_TotP_kg"] <- "internal P load"
fig4b_data$Source[fig4b_data$Source=="Pext_kg"] <- "external P load"
write.csv(fig4b_data, file="Products/Figure4b_data.csv")

### plot loads by year ###
fig4b<- ggplot(data=fig4b_data, aes(x=as.character(Yr), y=TotP_kg, fill=Source)) + #separate sources by fill color
  geom_bar(position="stack", stat="identity", color="black") + #stacked bar graph
  scale_fill_manual(values=c("black", "grey")) + #int=grey, ext=black
  theme_classic(base_size=10) +
  labs(x=NULL, y="Total P load (kg/yr)", title="b)") +
  theme(legend.position=c(0.15,0.9))
fig4b
```

Loads plotted.

c) plotting epilimnion total P concentrations...

```{r}
### summarize epi P concentrations by year ###
fig4c_data<- loads %>%
  filter(daynum>= 196 & daynum <= 252) %>% #filter for cyanoHAB season
  select(Yr, daynum, epi_totP_mgL)
write.csv(fig4c_data, file="Products/Figure4c_data.csv")

### plot epi P for season ###
fig4c<- ggplot(data=fig4c_data, aes(y=epi_totP_mgL, x=as.character(Yr))) +
  geom_boxplot() + 
  labs(x="Year", y="Epilimnion Total P (mg/L)", title="c)") +
  theme_classic() 
fig4c
```

Epi P plotted.

c) plotting all together and saving data...

```{r}
### plot all together ###
fig4<- ggarrange(fig4a, fig4b, fig4c, nrow=3, ncol=1)
fig4 #print the plot
ggsave(fig4, file="Products/Figure4.png")
```

# Step 6. Compare average annual P load between Pint and Pstreams...

```{r}
Pload_comp<- loads %>%
  group_by(Yr) %>%
  summarize(Pstreams_kgyr=sum(Pstreams_kgday),
            Int_TotP_kgyr=sum(Int_TotP_kgday))
mean(Pload_comp$Int_TotP_kgyr/Pload_comp$Pstreams_kgyr)

Pload_comp_dry<- Pload_comp %>%
  filter(Yr!=2016 & Yr!=2018)
mean(Pload_comp_dry$Int_TotP_kgyr/Pload_comp_dry$Pstreams_kgyr)

Pload_comp_wet<- Pload_comp %>%
  filter(Yr==2016 | Yr==2018)
mean(Pload_comp_wet$Int_TotP_kgyr/Pload_comp_wet$Pstreams_kgyr)
```

Comparison calculated.
