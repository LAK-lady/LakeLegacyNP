---
title: "Impact_model_inputs.Rmd"
author: "Lauren Knose"
date: "2024-06-01"
output: html_document
editor_options: 
  chunk_output_type: console
---

The purpose of this program is to prepare data for input into models.


# Step 1. Load dependent packages and data needed:

a) Loading dependent packages...
```{r}
library(zoo) #needed to interpolate NA values (na.approx function)
library(ggplot2) #needed for plots
library(ggpubr) #needed to plot two plots in one graph
library(dplyr) #needed for reshaping/reformating data
```

b) Loading data...
Note, ensure date data is formatted in R as Date.

```{r}
cyanoHAB<- read.csv(file="Cleaned_data/cyanoHAB_severity.csv")
extLoad<- read.csv(file="Cleaned_data/TotalP_allext.csv")
intLoad<- read.csv(file="Cleaned_data/TotalP_allint.csv")
```

# Step 2. Reformat the data: 

a) merging the load data files...
Note, you can only merge two files at one time.

```{r}
### select fields needed ###
intLoad2<- intLoad %>%
  select(!c(sampledate.x, sampledate.y))

extLoad2<- extLoad %>%
  select(!c(sampledate, dryP_atm_kgday, wetP_atm_kgday, totP_atm_kgday))

### merge load tables ###
loads<- merge(intLoad2, extLoad2, #daily estimates
               by.x=c("Yr", "daynum"), #key fields in x data frame
               by.y=c("Yr", "daynum"), #key fields in y data frame
               all=TRUE) #only keep records in x data frame
```

Data frames merged.

b) subsetting data to cyanoHAB season + 28 day lag...

```{r}
loads<- loads %>%
  filter(daynum >= 168 & daynum <= 252) #cyanoHAB season start - 28 days
```

Data subset.

# Step 3. Calculate average weekly loads:

a) defining the weekly observation sequence...

```{r}
### define the time sequence needed ###
week_bins<-seq(from=168, #define date start of CyanoHAB season
                  to=252, #define date end of CyanoHAB season
                  by=7) #creates a sequence every 1 day 
week_bins
```

Weekly observations determined.

b) bin observations by week...

```{r}
### bin data frame B to frequencies ###
loads<- loads %>%
  mutate(week_bin=
           ifelse(daynum<week_bins[2], #if observation is <= bin 2 min
                  week_bins[1], #yes returns bin 1
                  ifelse(daynum>=week_bins[2]&daynum<week_bins[3],
                         week_bins[2], 
                         ifelse(daynum>=week_bins[3]&daynum<week_bins[4],
                                week_bins[3], ifelse(daynum>=week_bins[4]&daynum<week_bins[5],
                                       week_bins[4],  ifelse(daynum>=week_bins[5]&daynum<week_bins[6],
                                       week_bins[5],  ifelse(daynum>=week_bins[6]&daynum<week_bins[7],
                                       week_bins[6],  ifelse(daynum>=week_bins[7]&daynum<week_bins[8],
                                       week_bins[7],  ifelse(daynum>=week_bins[8]&daynum<week_bins[9],
                                       week_bins[8],  ifelse(daynum>=week_bins[9]&daynum<week_bins[10],
                                       week_bins[9], ifelse(daynum>=week_bins[10]&daynum<week_bins[11],
                                       week_bins[10], ifelse(daynum>=week_bins[11]&daynum<week_bins[12],
                                       week_bins[11], ifelse(daynum>=week_bins[12]&daynum<week_bins[13],
                                       week_bins[12], week_bins[13])))))))))))))
```

Observations binned. 

c) calculating weekly loads...

```{r}
### summarize loads by week ###
all_x<- loads %>%
  group_by(Yr, week_bin) %>%
  summarize(avg_Pint=mean(Int_TotP_kgday, na.rm=TRUE),
            avg_Pext=mean(Pext_kgday, na.rm=TRUE),
            avg_Pextnoother=mean(Pext_kgday_noother, na.rm=TRUE),
            avg_epiP_mgL=mean(epi_totP_mgL, na.rm=TRUE),
            avgTotP_HEratio=mean(TotP_HEratio, na.rm=TRUE),
            Strat_TotP_kg=sum(Strat_TotP_kgday),
            Unstr_TotP_kg=sum(Unstr_TotP_kgday),
            Int_TotP_kg=sum(Int_TotP_kgday),
            Precip_in=sum(Precipitation_in),
            Patm_kg=sum(Patm_kgday),
            Pstreams_kg=sum(Pstreams_kgday),
            Pother_kg=sum(Pother_kgday),
            Pext_kg_noother=sum(Pext_kgday_noother),
            Pext_kg=sum(Pext_kgday)) %>%
  ungroup() %>%
  mutate(Pload_ratio=Int_TotP_kg/Pext_kg)#calculate the ratio of Pint/Pext
summary(all_x%>%filter(week_bin>=196&week_bin<=252))
```

Weekly loads calculated.

# Step 4. Add lagged values in new field:

```{r}
all_x<- all_x %>%
  mutate(avg_Pint_k7=lag(avg_Pint, n=1),
         avg_Pint_k14=lag(avg_Pint, n=2),
         avg_Pint_k21=lag(avg_Pint, n=3),
         avg_Pint_k28=lag(avg_Pint, n=4),
         avgTotP_HEratio_k7=lag(avgTotP_HEratio, n=1),
         avgTotP_HEratio_k14=lag(avgTotP_HEratio, n=2),
         avgTotP_HEratio_k21=lag(avgTotP_HEratio, n=3),
         avgTotP_HEratio_k28=lag(avgTotP_HEratio, n=4),
         avg_Pext_k7=lag(avg_Pext, n=1),
         avg_Pext_k14=lag(avg_Pext, n=2),
         avg_Pext_k21=lag(avg_Pext, n=3),
         avg_Pext_k28=lag(avg_Pext, n=4),
         avg_Pextnoother_k7=lag(avg_Pextnoother, n=1),
         avg_Pextnoother_k14=lag(avg_Pextnoother, n=2),
         avg_Pextnoother_k21=lag(avg_Pextnoother, n=3),
         avg_Pextnoother_k28=lag(avg_Pextnoother, n=4))
```

Lagged loads added.

# Step 5. Merge the response and predictor variables:

```{r}
inputs_weekly<- merge(all_x, cyanoHAB,
                 by.x=c("Yr", "week_bin"),
                 by.y=c("Yr", "week_bin"), all.y=TRUE)
```

Data files merged.

# Step 4. Save the data as new data files:

```{r}
### saving weekly data file ###
write.csv(inputs_weekly, file="Cleaned_data/Impact_model_weekly.csv")
```

# Step 5. View and summarize the data:

a) plotting internal loads by year...

```{r}
### select fields needed ###
int_intputs_yr<- inputs_weekly %>%
  select(Yr, week_bin, Strat_TotP_kg, Unstr_TotP_kg) %>%
  melt(int_intputs_yr, #the table you want to reshape wide to long
               id.vars=c("Yr", "week_bin"), #the column to use as unique id
               measure.vars=c("Strat_TotP_kg","Unstr_TotP_kg"), 
               #the columns where values will be taken
               variable.name="Source", #label the source of P loading
               value.name="TotP_kg") #label the value with units

### rename source loads ###               
int_intputs_yr$Source<-as.character(int_intputs_yr$Source) #tell R character data held
int_intputs_yr$Source[int_intputs_yr$Source=="Strat_TotP_kg"] <- "stratified region"
int_intputs_yr$Source[int_intputs_yr$Source=="Unstr_TotP_kg"] <- "unstratified region"

### calculate the total annual loads ###
int_intputs_yr<- int_intputs_yr %>%
  group_by(Yr, Source) %>% #for each year and each source
  summarize(TotP_kgyr=sum(TotP_kg)) %>%#sum up all the TotP_kgday
  ungroup()

### plot the annual internal loads by source ###
SI_fig18<- ggplot(int_intputs_yr, aes(x=Yr, y=TotP_kgyr, 
                             fill=Source)) + #separate sources by fill color
  geom_bar(position="stack", stat="identity", color="black") + #stacked bar graph
  scale_fill_manual(values=c("grey", "black")) + #entrain = grey, sed=black
  theme_classic(base_size=12) +
  labs(x="Year", y="Total P loading (kg/yr)") 
SI_fig18 #print the plot
ggsave(SI_fig18, file="Products/SI_figures/Figure18.png")
```

Total P load by source for each year plotted.

b) plotting P loads against epi P concentration...

```{r}
### create data table for plots ###
fig4_data<- inputs_weekly %>%
  select(Yr, week_bin, avg_epiP_mgL, Int_TotP_kg, Pext_kg)

fig4a<- fig4_data %>%
  select(Yr, Int_TotP_kg, Pext_kg) %>%
  melt(fig4a, #the table you want to reshape wide to long
               id.vars=c("Yr"), #the column to use as unique id
               measure.vars=c("Int_TotP_kg","Pext_kg"), 
               #the columns where values will be taken
               variable.name="Source", #label the source of P loading
               value.name="TotP_kg") #label the value with units

### rename source loads ###               
fig4a$Source<-as.character(fig4a$Source) #tell R character data held
fig4a$Source[fig4a$Source=="Int_TotP_kg"] <- "internal P load"
fig4a$Source[fig4a$Source=="Pext_kg"] <- "external P load"

### calculate the total annual loads ###
inputs_yr<- fig4a %>%
  group_by(Yr, Source) %>% #for each year and each source
  summarize(TotP_kgyr=sum(TotP_kg)) %>%#sum up all the TotP_kgday
  ungroup()

### create top plot ###
fig4a<- ggplot(data=inputs_yr, aes(x=as.character(Yr), y=TotP_kgyr, fill=Source)) + #separate sources by fill color
  geom_bar(position="stack", stat="identity", color="black") + #stacked bar graph
  scale_fill_manual(values=c("black", "grey")) + #int=grey, ext=black
  theme_classic(base_size=12) +
  labs(x="Year", y="Total P load (kg/yr)", title="a)") +
  theme(legend.position=c(0.15,0.90))
fig4a

fig4b<- ggplot(data=fig4_data, aes(y=avg_epiP_mgL, x=as.character(Yr))) +
  geom_boxplot() + 
  labs(x="Year", y="Epilimnion Total P (mg/L)", title="b)") +
  theme_classic() 
fig4b
fig4<- ggarrange(fig4a, fig4b, nrow=2, ncol=1)
fig4 #print the plot
ggsave(fig4, file="Products/Figure4.png")
```

# Step 6. Compare average annual P load between Pint and Pstreams...

```{r}
Pload_comp<- inputs_weekly %>%
  group_by(Yr) %>%
  summarize(Pstreams_kgyr=sum(Pstreams_kg),
            Int_TotP_kgyr=sum(Int_TotP_kg))
mean(Pload_comp$Int_TotP_kgyr/Pload_comp$Pstreams_kgyr)

Pload_comp_dry<- Pload_comp %>%
  filter(Yr!=2016 & Yr!=2018)
mean(Pload_comp_dry$Int_TotP_kgyr/Pload_comp_dry$Pstreams_kgyr)

Pload_comp_wet<- Pload_comp %>%
  filter(Yr==2016 | Yr==2018)
mean(Pload_comp_wet$Int_TotP_kgyr/Pload_comp_wet$Pstreams_kgyr)
```

Comparison calculated.
