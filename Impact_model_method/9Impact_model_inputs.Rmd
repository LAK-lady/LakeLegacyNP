---
title: "Impact_model_inputs.Rmd"
author: "Lauren Knose"
date: "2024-06-01"
output: html_document
editor_options: 
  chunk_output_type: console
---

The purpose of this program is to prepare data for input into models.


# Step 1. Load dependent packages and data needed:

a) Loading dependent packages...
```{r}
library(zoo) #needed to interpolate NA values (na.approx function)
library(ggplot2) #needed for plots
library(ggpubr) #needed to plot two plots in one graph
library(dplyr) #needed for reshaping/reformating data
```

b) Loading data...
Note, ensure date data is formatted in R as Date.

```{r}
cyanoHAB<- read.csv(file="Cleaned_data/cyanoHAB_severity.csv")
extLoad<- read.csv(file="Cleaned_data/TotalP_allext.csv")
intLoad<- read.csv(file="Cleaned_data/TotalP_allint.csv")
```

# Step 2. Calculate weekly loads: 

a) merging and filtering data...
Note, you can only merge two files at one time.

```{r}
### remove unecessary fields ###
intLoad2<- intLoad %>%
  mutate(sampledate.x=NULL, sampledate.y=NULL, X=NULL)

extLoad2<- extLoad %>%
  select(!c(sampledate, dryP_atm_kgday, wetP_atm_kgday, totP_atm_kgday, X))

### merge load tables ###
loads<- merge(intLoad2, extLoad2, #daily estimates
               by.x=c("Yr", "daynum"), #key fields in x data frame
               by.y=c("Yr", "daynum"), #key fields in y data frame
               all=TRUE)
### filter data ###
loads<- loads %>%
  filter(daynum>=161 & daynum <= 252) #season +- buffer
```

Data frames merged.

b) defining the weekly observation sequence...

```{r}
### define the time sequence needed ###
week_bins<-seq(from=161, 
                  to=252, #define date end of cyanoHAB season
                  by=7) #creates a sequence every 7 days 
week_bins
```

Weekly observation bins determined as sequence 1 to 14.

d) bin loads to following week...

```{r}
### bin to frequencies using nested if/else functions ###
loads<- loads %>%
  mutate(week_bin=
           ifelse(daynum<=week_bins[14]&daynum>week_bins[13], #if observation is <= bin 2 min
                  week_bins[14], #yes returns bin 1
              ifelse(daynum<=week_bins[13]&daynum>week_bins[12],
                         week_bins[13],
                     ifelse(daynum<=week_bins[12]&daynum>week_bins[11],
                                week_bins[12], ifelse(daynum<=week_bins[11]&daynum>week_bins[10],
                                       week_bins[11],  ifelse(daynum<=week_bins[10]&daynum>week_bins[9],
                                       week_bins[10],  ifelse(daynum<=week_bins[9]&daynum>week_bins[8],
                                       week_bins[9],  ifelse(daynum<=week_bins[8]&daynum>week_bins[7],
                                       week_bins[8],  ifelse(daynum<=week_bins[7]&daynum>week_bins[6],
                                       week_bins[7],  ifelse(daynum<=week_bins[6]&daynum>week_bins[5],
                                       week_bins[6], ifelse(daynum<=week_bins[5]&daynum>week_bins[4],
                                       week_bins[5], ifelse(daynum<=week_bins[4]&daynum>week_bins[3],
                                       week_bins[4], ifelse(daynum<=week_bins[3]&daynum>week_bins[2],
                                       week_bins[3],
                                       ifelse(daynum<=week_bins[2]&daynum>week_bins[1],
                                              week_bins[2],
                                              week_bins[1]))))))))))))))
```

Observations binned. 

c) calculating average weekly loads...

```{r}
### average loads by week ###
all_x<- loads %>%
  group_by(Yr, week_bin) %>%
  summarize(Pint=sum(Int_TotP_kgday),
            Pext=sum(Pext_kgday),
            avgTotP_HEratio=mean(TotP_HEratio, na.rm=TRUE)) %>% 
  ungroup()
```

Weekly loads calculated.

# Step 4. Add lagged values in new field:

```{r}
### add lagged values ###
all_x2<- all_x %>%
  mutate(Pint_k7=lag(Pint, n=1),
         Pint_k14=lag(Pint, n=2),
         Pint_k21=lag(Pint, n=3),
         Pint_k28=lag(Pint, n=4),
         Pext_k7=lag(Pext, n=1),
         Pext_k14=lag(Pext, n=2),
         Pext_k21=lag(Pext, n=3),
         Pext_k28=lag(Pext, n=4),
         avgTotP_HEratio_k7=lag(avgTotP_HEratio, n=1),
         avgTotP_HEratio_k14=lag(avgTotP_HEratio, n=2),
         avgTotP_HEratio_k21=lag(avgTotP_HEratio, n=3),
         avgTotP_HEratio_k28=lag(avgTotP_HEratio, n=4),) %>% 
  ungroup()

### filter out NAs ###
all_x2<- all_x2 %>% filter(week_bin>= 196 & week_bin <= 252)
```

Lagged loads added.

# Step 5. Merge the response and predictor variables:

```{r}
inputs_weekly<- merge(all_x2, cyanoHAB,
                 by.x=c("Yr", "week_bin"),
                 by.y=c("Yr", "daynum_bin"), all.y=TRUE)
```

Data files merged.

# Step 4. Save the data as new data files:

```{r}
### saving weekly data file ###
write.csv(inputs_weekly, file="Cleaned_data/Impact_model_weekly.csv")
```

# Step 5. View and summarize the data:

a) plotting precipitation for season by year...

```{r}
### summarize precipitation by year ###
fig4a_data<- loads %>%
  filter(daynum>=196 & daynum<=252) %>% #filter for cyanoHAB season
  select(Yr, Precipitation_in) %>%
  group_by(Yr) %>%
  summarize(Precip_inyr=sum(Precipitation_in)) %>%
  ungroup()
write.csv(fig4a_data, file="Products/Figure4a_data.csv")

### plot precipitation per year for cyanoHAB season ###
fig4a<- ggplot(data=fig4a_data, aes(x=as.character(Yr), y=Precip_inyr)) + 
  geom_bar(stat="identity", color="black", fill="grey")+ 
  theme_classic()+
  labs(x=NULL, y="Total Precipitation (in)", title="a)")
fig4a
```

Precipitation plotted.

b) plotting P loads for season by source and year...

```{r}
### sumarize loads by year ###
fig4b_data<- loads %>%
  filter(daynum>= 196 & daynum <= 252) %>% #filter for cyanoHAB season
  select(Yr, daynum, Int_TotP_kgday, Pext_kgday) %>%
  group_by(Yr) %>% # summarize by year
  summarize(Int_TotP_kg=sum(Int_TotP_kgday), 
            Pext_kg=sum(Pext_kgday)) %>%
  ungroup()
fig4b_data<- melt(fig4b_data, #the table you want to reshape wide to long
               id.vars=c("Yr"), #the column to use as unique id
               measure.vars=c("Int_TotP_kg","Pext_kg"), 
               #the columns where values will be taken
               variable.name="Source", #label the source of P loading
               value.name="TotP_kg") #label the value with units

### rename source loads ###               
fig4b_data$Source<-as.character(fig4b_data$Source) #tell R character data held
fig4b_data$Source[fig4b_data$Source=="Int_TotP_kg"] <- "internal P load"
fig4b_data$Source[fig4b_data$Source=="Pext_kg"] <- "external P load"
write.csv(fig4b_data, file="Products/Figure4b_data.csv")

### plot loads by year ###
fig4b<- ggplot(data=fig4b_data, aes(x=as.character(Yr), y=TotP_kg, fill=Source)) + #separate sources by fill color
  geom_bar(position="stack", stat="identity", color="black") + #stacked bar graph
  scale_fill_manual(values=c("black", "grey")) + #int=grey, ext=black
  theme_classic(base_size=10) +
  labs(x=NULL, y="Total P load (kg/yr)", title="b)") +
  theme(legend.position=c(0.15,0.9))
fig4b
```

Loads plotted.

c) plotting epilimnion total P concentrations...

```{r}
### summarize epi P concentrations by year ###
fig4c_data<- loads %>%
  filter(daynum>= 196 & daynum <= 252) %>% #filter for cyanoHAB season
  select(Yr, daynum, epi_totP_mgL)
write.csv(fig4c_data, file="Products/Figure4c_data.csv")

### plot epi P for season ###
fig4c<- ggplot(data=fig4c_data, aes(y=epi_totP_mgL, x=as.character(Yr))) +
  geom_boxplot() + 
  labs(x="Year", y="Epilimnion Total P (mg/L)", title="c)") +
  theme_classic() 
fig4c
```

Epi P plotted.

c) plotting all together and saving data...

```{r}
### plot all together ###
fig4<- ggarrange(fig4a, fig4b, fig4c, nrow=3, ncol=1)
fig4 #print the plot
ggsave(fig4, file="Products/Figure4.png")
```

# Step 6. Compare average annual P load between Pint and Pstreams...

```{r}
Pload_comp<- loads %>%
  group_by(Yr) %>%
  summarize(Pstreams_kgyr=sum(Pstreams_kgday),
            Int_TotP_kgyr=sum(Int_TotP_kgday))
mean(Pload_comp$Int_TotP_kgyr/Pload_comp$Pstreams_kgyr)

Pload_comp_dry<- Pload_comp %>%
  filter(Yr!=2016 & Yr!=2018)
mean(Pload_comp_dry$Int_TotP_kgyr/Pload_comp_dry$Pstreams_kgyr)

Pload_comp_wet<- Pload_comp %>%
  filter(Yr==2016 | Yr==2018)
mean(Pload_comp_wet$Int_TotP_kgyr/Pload_comp_wet$Pstreams_kgyr)
```

Comparison calculated.
