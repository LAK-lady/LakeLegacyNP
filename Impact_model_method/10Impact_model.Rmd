---
title: "Impact_model.Rmd"
author: "Lauren A. Knose, ORISE-EPA"
date: '2024-06-10'
output: html_document
editor_options: 
  chunk_output_type: console
---

The purpose of this program is to perform an impact analysis comparing the internal vs external P loading on changes in Chl-a and CyanoDensity.


# Step 1. Load dependent packages and data needed:

a) Loading dependent packages...
```{r}
library(dplyr) #needed for reshaping/reformating data
library(reshape2) #needed for reshaping data frames
library(ggplot2) #needed for plotting and saving plots
library(car) #needed to get model VIFs
library(ggpubr)
library(ggpattern) #needed to add patterns to barplots
```

Packages loaded.

b) Loading data...

```{r}
### loading the data ###
weekly<- read.csv(file="Cleaned_data/Impact_model_weekly.csv")

### bound data to cyanoHAB season ###
weekly<- weekly %>% filter(daynum>=196 & daynum <=252)
```

Data loaded.

# Step 2. Define predictors (transformations and lags):

a) defining predictor lags and transformation...

```{r}
### checking linear correlation with response, vary lags as needed ###
SIfig13a<- ggscatter(data=weekly,
          x="CD_cellsmL_k7",y="CD_cellsmL", 
          add="reg.line", conf.int=TRUE, cor.coef=TRUE, cor.method="pearson",
          xlab="CD (cells/mL), lagged 1 week", ylab="CD (cells/mL)")

SIfig13b<-ggscatter(data=weekly,
          x="Pint_k21",y="CD_cellsmL", 
          add="reg.line", conf.int=TRUE, cor.coef=TRUE, cor.method="pearson",
          xlab="Pint, lagged 3 weeks", ylab="CD (cells/mL)")+ xscale("log10", .format=TRUE)

SIfig13c<- ggscatter(data=weekly,
          x="Pext_k28",y="CD_cellsmL", 
          add="reg.line", conf.int=TRUE, cor.coef=TRUE, cor.method="pearson",
          xlab="Pext, lagged 4 weeks", ylab="CD (cells/mL)")+ xscale("log10", .format=TRUE)

SIfig13<- ggarrange(SIfig13a, SIfig13b, SIfig13c, nrow=3, ncol=1)
SIfig13
write.csv(weekly, file="Products/SI_figures/Figure13_data.csv")
ggsave(SIfig13, file="Products/SI_figures/Figure13.png")
```

Predictor lags defined.

b) checking for normality...

```{r}
par(mfrow=c(2,4), mar=c(4,4,4,4))
hist(weekly$Chla_ugL, breaks=18,#histograph of Chl-a
     main="non-transformed", xlab="Chl-a") 
hist(weekly$CD_cellsmL, breaks=18,#histograph of CD
     main="non-transformed", xlab="CD") 
hist(weekly$Pext_k28, breaks=18,#histogrpah of P_ext
     main="non-transformed", xlab="P_ext_k28") 
hist(weekly$Pint_k21, breaks=18,#histograph of P_int
     main="non-transformed", xlab="P_int_k21") 
hist(log10(weekly$Chla_ugL), breaks=18,#histograph of log10(Chl-a)
     main="log-transformed", xlab="Chl-a") 
hist(log10(weekly$CD_cellsmL), breaks=18,#histograph of log10(CD)
     main="log-transformed", xlab="CD") 
hist(log10(weekly$Pext_k28), breaks=18,#histograph of log10(P_ext)
     main="log-transformed", xlab="P_ext_k28") 
hist(log10(weekly$Pint_k21), breaks=18,#histograph of log10(P_int)
     main="log-transformed", xlab="P_int_k21") 
par(mfrow=c(1,1)) #return to default
#save manually as SI-fig14
```

Comparison of non-transformed and transformed data graphed.

# Step 3. Run regression:

a) running model: CD_t ~ log10(P_int, t-k) + log10(P_ext,t-k) + error

```{r}
### define the model ###
regka_CD<- glm(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=weekly)

### print model AIC ###
summary(regka_CD)

### print model R^2 ###
summary(lm(regka_CD))
```

Model defined.

b) running model diagnostics...

```{r}
### print model diagnostics ###
par(mfrow=c(3,2), mar=c(4,4,4,4))
plot(regka_CD)

### plot expected vs observed ###
plot(x=predict(regka_CD), y=weekly$CD_cellsmL, 
    xlab="Predicted Values", ylab="Observed Values", main="Predicted vs Observed")
abline(a=0,b=1) #add 1:1 line to plot
# save as SIfig15
par(mfrow=c(1,1)) #return par to default

### remove outliers if necessary ###
weekly<- weekly[-c(38, 22),] #outlier identified in diagnostics

### print model VIFs ###
vif(regka_CD) #prints the VIFs 
```

Model diagnostics complete.

# Step 4. Calculate the partial sum squares for each year:

a) calculating partial squares for each year...

```{r}
### define the model ###
YRregk_CD_2013<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2013)) #subset data by year
            
### print the Sum of Squares as table ###
SS_2013<- summary(YRregk_CD_2013)
impact2013<- data.frame(SS_2013[[1]])[,2,drop=FALSE] #pulls out the SS as table

### define the model ###
YRregk_CD_2014<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2014)) #subset data by year

### print the Sum of Squares as table ###
SS_2014<- summary(YRregk_CD_2014)#prints the sum of squares for the regression 
impact2014<- data.frame(SS_2014[[1]])[,2,drop=FALSE] #pulls out the SS as table

### define the model ###
YRregk_CD_2015<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2015)) #subset data by year

### print the Sum of Squares as table ###
SS_2015<- summary(YRregk_CD_2015)#prints the sum of squares for the regression 
impact2015<- data.frame(SS_2015[[1]])[,2,drop=FALSE] #pulls out the SS as table

### define the model ###
YRregk_CD_2016<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2016)) #subset data by year

### print the Sum of Squares as table ###
SS_2016<- summary(YRregk_CD_2016)#prints the sum of squares for the regression 
impact2016<- data.frame(SS_2016[[1]])[,2,drop=FALSE] #pulls out the SS as table

### define the model ###
YRregk_CD_2017<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2017)) #subset data by year

### print the Sum of Squares as table ###
SS_2017<- summary(YRregk_CD_2017)#prints the sum of squares for the regression 
impact2017<- data.frame(SS_2017[[1]])[,2,drop=FALSE] #pulls out the SS as table

### define the model ###
YRregk_CD_2018<- aov(formula=CD_cellsmL~CD_cellsmL_k7+log10(Pint_k21)+log10(Pext_k28), data=subset(weekly, Yr==2018)) #subset data by year

### print the Sum of Squares as table ###
SS_2018<- summary(YRregk_CD_2018)#prints the sum of squares for the regression 
impact2018<- data.frame(SS_2018[[1]])[,2,drop=FALSE] #pulls out the SS as table
```

Partial Sum Squares calculated for each year.

c) combining the SSR into one data file...

```{r}
### merging the Sum Squares tables ###
Model_output_CD<- cbind(impact2013, impact2014, impact2015, impact2016, impact2017, impact2018) #combines all tables together
Model_output_CD$Sum_Sq_part<- c("Seed Stock", "Internal load","External load", "Residual") #add column with predictor name
colnames(Model_output_CD)<- c("2013", "2014", "2015", "2016", "2017", "2018", "Sum_Sq_part") # renames columns with year for sum squares
write.csv(Model_output_CD, file="Products/Figure5a_data.csv") #save figure data file

### print SS table as bar plot for baseline ###
CD_table<- melt(Model_output_CD, id.vars="Sum_Sq_part", variable.name = "Year", value.name = "PSS") %>%
  mutate(Sum_Sq_part=factor(Sum_Sq_part, 
                            levels=c("Residual", "Seed Stock", "External load",  "Internal load"), 
                            ordered=TRUE))
```

SS combined.

d) plotting the SS...

```{r}
### plot the output ###
fig5a<- ggplot(data=CD_table, aes(y=PSS, x=Year, pattern=Sum_Sq_part, fill=Sum_Sq_part)) +
  geom_bar_pattern(position="fill", stat="identity") +
  labs(y="Sum of Squares for Regression", pattern="Predictor",title="a) Variance by Year") +
  guides(fill="none") +
  theme_classic()+
  theme(legend.position="bottom")+
  scale_pattern_manual(values=c('crosshatch','stripe','wave','circle'))
fig5a
```

Yearly source-attributed impact outputted.

# Step 5. Predict the change in cyanoHAB severity:

a) creating new data based on counterfactuals and model predicted responses...

```{r}
### define counterfactual scenario 1 ###
CF1<- data.frame(Pext_k28=weekly$Pext_CF1_k28,
                 Pint_k21=weekly$Pint_k21,
                 CD_cellsmL_k7=weekly$CD_cellsmL_k7)
CF1$predicted<- predict(regka_CD, newdata=CF1, interval='confidence')

### define counterfactual scenario 2 ###
CF2<- data.frame(Pext_k28=(weekly$Pext_k28*0.1),
                 Pint_k21=weekly$Pint_k21,
                 CD_cellsmL_k7=weekly$CD_cellsmL_k7)
CF2$predicted<- predict(regka_CD, newdata=CF2, interval='confidence')

### define counterfactual scenario 3 ###
CF3<- data.frame(Pext_k28=weekly$Pext_k28,
                 Pint_k21=(weekly$Pint_k21*0.1),
                 CD_cellsmL_k7=weekly$CD_cellsmL_k7)
CF3$predicted<- predict(regka_CD, newdata=CF3, interval='confidence')
```

Counterfactuals modeled.

b) merging new data...

```{r}
### select key fields ###
comp_df<- weekly %>% select(Yr, daynum, CD_cellsmL)
CF1<- CF1 %>% select(predicted)
CF2<- CF2 %>% select(predicted)
CF3<- CF3 %>% select(predicted)

### merge data frames ###
Severity<- comp_df %>%
  rename(Baseline=CD_cellsmL) %>%
  mutate(CF1=CF1$predicted,
         CF2=CF2$predicted,
         CF3=CF3$predicted)

### transform wide to long format ##
Severity_long<- melt(Severity, id.vars=c("Yr","daynum"), variable.name="Scenario", value.name="CD_cellsmL")
```

New data merged.

c) plotting results...

```{r}
### plot time series ###
#ggplot(data=Severity_long, aes(x=daynum, y=CD_cellsmL/10000, group=Scenario)) +
#  facet_wrap(~Yr)+
#  geom_point(aes(shape=Scenario, color=Scenario))+
#  geom_line(aes(linetype=Scenario, color=Scenario))+
#  scale_linetype_manual(values=c("solid","dashed","twodash","dotted"))+
#  scale_color_manual(values=c("black","darkorange","darkred", "darkgreen"))+
#  labs(x="Day", y=NULL, title="b) CyanoHAB severity (10^4 cells/mL)") +
#  theme_classic() +
#  theme(legend.position="bottom")

### alternatively a boxplot series ###
comparisons<- list(c("Baseline", "CF1"), c("Baseline", "CF2"), c("Baseline", "CF3"))
fig5b<- ggplot(data=Severity_long, aes(x=Scenario, y=CD_cellsmL/10000, group=Scenario)) +
  geom_violin(aes(col=Scenario), trim=FALSE)+
  scale_color_manual(values=c("black","darkorange","darkred", "darkgreen"))+
  labs(y="x10^4 cells/mL", title="b) Cyanobacteria Cell Density") +
  theme_classic() +
  theme(legend.position="bottom") +
  stat_compare_means(comparisons=comparisons, method="t.test", label="p.signif")
fig5b
write.csv(Severity_long, file="Products/Figure5b_data.csv")
```

d) combining figures...

```{r}
fig5<- ggarrange(fig5a, fig5b, nrow=1, ncol=2)
fig5
ggsave(fig3, file="Products/Figure5_color.png")
```

Figures combined

e) printing scenario summary stats...

```{r}
sum<- Severity_long %>% 
  group_by(Scenario) %>% 
  summarize(avg=mean(CD_cellsmL),
            se=sd(CD_cellsmL)/sqrt(length(CD_cellsmL)))
sum
```
Summary stats printed.
